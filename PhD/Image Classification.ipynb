{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "physical-tenant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#load data and packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as json\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D,MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "with open('/Users/mattvalko/Documents/PHD/metadata.json',encoding=\"latin-1\") as json_data:\n",
    "    data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "resistant-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the background data /file directory\n",
    "info = pd.json_normalize(data[\"annotations\"])\n",
    "label = pd.json_normalize(data[\"categories\"])\n",
    "files = pd.json_normalize(data[ \"images\"])\n",
    "files['folder']=files['file_name'].str[7:10]\n",
    "fullDF = files[files[\"folder\"].astype(int) < 11]\n",
    "merged=info.merge(fullDF,on='id',how=\"inner\")\n",
    "cnts=merged.groupby(['category_id'])['id'].count()\n",
    "catIDS=cnts[cnts > 700]#.index\n",
    "final = merged[merged['category_id'].isin(catIDS.index)]\n",
    "imgDir=final['file_name'].str[7::]\n",
    "imgDir=np.array(imgDir)\n",
    "path='/Users/mattvalko/Documents/PHD/examdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reserved-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the label for classification\n",
    "label=np.array(final['category_id'])\n",
    "u, y_train = np.unique(label, return_inverse=True)\n",
    "classNum=len(catIDS)\n",
    "y_train = keras.utils.to_categorical(y_train, classNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "differential-couple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "piano-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "data = [] \n",
    "img_height,img_width = 100,100 \n",
    "for i in range(0,len(imgDir)):\n",
    "    img_arr = cv2.imread(os.path.join(path, imgDir[i]))\n",
    "    resized_arr = cv2.resize(img_arr, (img_height,img_width))\n",
    "    data.append(resized_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "royal-debate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4745098 ],\n",
       "         [0.52941176],\n",
       "         [0.41568627],\n",
       "         ...,\n",
       "         [0.49411765],\n",
       "         [0.36078431],\n",
       "         [0.53333333]],\n",
       "\n",
       "        [[0.63137255],\n",
       "         [0.42745098],\n",
       "         [0.57254902],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.95294118],\n",
       "         [0.95294118],\n",
       "         [0.91764706]]],\n",
       "\n",
       "\n",
       "       [[[0.94117647],\n",
       "         [0.94901961],\n",
       "         [0.96078431],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.95686275],\n",
       "         [0.95686275]],\n",
       "\n",
       "        [[0.95294118],\n",
       "         [0.75686275],\n",
       "         [0.81568627],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.31764706],\n",
       "         [0.38039216],\n",
       "         [0.87058824]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.96078431],\n",
       "         [0.95294118],\n",
       "         [0.96078431],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.94901961],\n",
       "         [0.94901961],\n",
       "         [0.94117647]],\n",
       "\n",
       "        [[0.94901961],\n",
       "         [0.94901961],\n",
       "         [0.94509804],\n",
       "         ...,\n",
       "         [0.96078431],\n",
       "         [0.95294118],\n",
       "         [0.96078431]]],\n",
       "\n",
       "\n",
       "       [[[0.96078431],\n",
       "         [0.95294118],\n",
       "         [0.96078431],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.94901961],\n",
       "         [0.94901961],\n",
       "         [0.94117647]],\n",
       "\n",
       "        [[0.94901961],\n",
       "         [0.94901961],\n",
       "         [0.94117647],\n",
       "         ...,\n",
       "         [0.96078431],\n",
       "         [0.95294118],\n",
       "         [0.96078431]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.03529412],\n",
       "         [0.03137255],\n",
       "         [0.03921569],\n",
       "         ...,\n",
       "         [0.1372549 ],\n",
       "         [0.19215686],\n",
       "         [0.05098039]],\n",
       "\n",
       "        [[0.05882353],\n",
       "         [0.03529412],\n",
       "         [0.03529412],\n",
       "         ...,\n",
       "         [0.03921569],\n",
       "         [0.04705882],\n",
       "         [0.03529412]],\n",
       "\n",
       "        [[0.04313725],\n",
       "         [0.03921569],\n",
       "         [0.02745098],\n",
       "         ...,\n",
       "         [0.03921569],\n",
       "         [0.03137255],\n",
       "         [0.03137255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.94509804],\n",
       "         [0.93333333],\n",
       "         [0.90980392],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.92156863],\n",
       "         [0.95686275]],\n",
       "\n",
       "        [[0.94509804],\n",
       "         [0.92156863],\n",
       "         [0.95686275],\n",
       "         ...,\n",
       "         [0.03921569],\n",
       "         [0.03137255],\n",
       "         [0.03137255]],\n",
       "\n",
       "        [[0.03529412],\n",
       "         [0.03137255],\n",
       "         [0.03921569],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.93333333],\n",
       "         [0.90980392]]],\n",
       "\n",
       "\n",
       "       [[[0.94509804],\n",
       "         [0.93333333],\n",
       "         [0.91764706],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.92156863],\n",
       "         [0.95686275]],\n",
       "\n",
       "        [[0.94509804],\n",
       "         [0.91764706],\n",
       "         [0.95294118],\n",
       "         ...,\n",
       "         [0.03921569],\n",
       "         [0.03137255],\n",
       "         [0.03137255]],\n",
       "\n",
       "        [[0.03921569],\n",
       "         [0.03529412],\n",
       "         [0.04313725],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.93333333],\n",
       "         [0.90980392]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.94509804],\n",
       "         [0.94117647],\n",
       "         [0.96470588],\n",
       "         ...,\n",
       "         [0.05098039],\n",
       "         [0.02745098],\n",
       "         [0.03137255]],\n",
       "\n",
       "        [[0.03137255],\n",
       "         [0.02745098],\n",
       "         [0.03529412],\n",
       "         ...,\n",
       "         [0.52941176],\n",
       "         [0.59215686],\n",
       "         [0.23137255]],\n",
       "\n",
       "        [[0.32156863],\n",
       "         [0.38039216],\n",
       "         [0.34509804],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.94117647],\n",
       "         [0.96470588]]],\n",
       "\n",
       "\n",
       "       [[[0.94509804],\n",
       "         [0.94117647],\n",
       "         [0.96470588],\n",
       "         ...,\n",
       "         [0.02745098],\n",
       "         [0.01960784],\n",
       "         [0.01960784]],\n",
       "\n",
       "        [[0.03137255],\n",
       "         [0.02745098],\n",
       "         [0.03529412],\n",
       "         ...,\n",
       "         [0.43529412],\n",
       "         [0.4745098 ],\n",
       "         [0.29411765]],\n",
       "\n",
       "        [[0.3372549 ],\n",
       "         [0.39215686],\n",
       "         [0.32941176],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.93333333],\n",
       "         [0.95294118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0627451 ],\n",
       "         [0.05882353],\n",
       "         [0.06666667],\n",
       "         ...,\n",
       "         [0.03137255],\n",
       "         [0.03137255],\n",
       "         [0.05490196]],\n",
       "\n",
       "        [[0.04705882],\n",
       "         [0.04705882],\n",
       "         [0.04313725],\n",
       "         ...,\n",
       "         [0.04705882],\n",
       "         [0.05490196],\n",
       "         [0.04705882]],\n",
       "\n",
       "        [[0.04705882],\n",
       "         [0.06666667],\n",
       "         [0.05882353],\n",
       "         ...,\n",
       "         [0.02745098],\n",
       "         [0.01960784],\n",
       "         [0.01960784]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Normalize the data\n",
    "x_feat=np.array(data)\n",
    "x_train = x_feat / 255\n",
    "\n",
    "\n",
    "x_train.reshape(-1,img_height,img_width, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acute-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Keras packages\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from urllib.request import urlopen,urlretrieve\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.datasets import load_files   \n",
    "from keras.utils import np_utils\n",
    "from glob import glob\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras import optimizers\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n",
    "num_classes = classNum\n",
    "from keras.optimizers import SGD, Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "supported-prize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattvalko/anaconda3/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#If imagenet weights are being loaded, \n",
    "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
    "base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worse-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "handy-daisy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4745098 ],\n",
       "         [0.52941176],\n",
       "         [0.41568627],\n",
       "         ...,\n",
       "         [0.49411765],\n",
       "         [0.36078431],\n",
       "         [0.53333333]],\n",
       "\n",
       "        [[0.63137255],\n",
       "         [0.42745098],\n",
       "         [0.57254902],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.95294118],\n",
       "         [0.95294118],\n",
       "         [0.91764706]]],\n",
       "\n",
       "\n",
       "       [[[0.94117647],\n",
       "         [0.94901961],\n",
       "         [0.96078431],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.95686275],\n",
       "         [0.95686275]],\n",
       "\n",
       "        [[0.95294118],\n",
       "         [0.75686275],\n",
       "         [0.81568627],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.31764706],\n",
       "         [0.38039216],\n",
       "         [0.87058824]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.96078431],\n",
       "         [0.95294118],\n",
       "         [0.96078431],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.94901961],\n",
       "         [0.94901961],\n",
       "         [0.94117647]],\n",
       "\n",
       "        [[0.94901961],\n",
       "         [0.94901961],\n",
       "         [0.94509804],\n",
       "         ...,\n",
       "         [0.96078431],\n",
       "         [0.95294118],\n",
       "         [0.96078431]]],\n",
       "\n",
       "\n",
       "       [[[0.96078431],\n",
       "         [0.95294118],\n",
       "         [0.96078431],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.94901961],\n",
       "         [0.94901961],\n",
       "         [0.94117647]],\n",
       "\n",
       "        [[0.94901961],\n",
       "         [0.94901961],\n",
       "         [0.94117647],\n",
       "         ...,\n",
       "         [0.96078431],\n",
       "         [0.95294118],\n",
       "         [0.96078431]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.03529412],\n",
       "         [0.03137255],\n",
       "         [0.03921569],\n",
       "         ...,\n",
       "         [0.1372549 ],\n",
       "         [0.19215686],\n",
       "         [0.05098039]],\n",
       "\n",
       "        [[0.05882353],\n",
       "         [0.03529412],\n",
       "         [0.03529412],\n",
       "         ...,\n",
       "         [0.03921569],\n",
       "         [0.04705882],\n",
       "         [0.03529412]],\n",
       "\n",
       "        [[0.04313725],\n",
       "         [0.03921569],\n",
       "         [0.02745098],\n",
       "         ...,\n",
       "         [0.03921569],\n",
       "         [0.03137255],\n",
       "         [0.03137255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.94509804],\n",
       "         [0.93333333],\n",
       "         [0.90980392],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.92156863],\n",
       "         [0.95686275]],\n",
       "\n",
       "        [[0.94509804],\n",
       "         [0.92156863],\n",
       "         [0.95686275],\n",
       "         ...,\n",
       "         [0.03921569],\n",
       "         [0.03137255],\n",
       "         [0.03137255]],\n",
       "\n",
       "        [[0.03529412],\n",
       "         [0.03137255],\n",
       "         [0.03921569],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.93333333],\n",
       "         [0.90980392]]],\n",
       "\n",
       "\n",
       "       [[[0.94509804],\n",
       "         [0.93333333],\n",
       "         [0.91764706],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.92156863],\n",
       "         [0.95686275]],\n",
       "\n",
       "        [[0.94509804],\n",
       "         [0.91764706],\n",
       "         [0.95294118],\n",
       "         ...,\n",
       "         [0.03921569],\n",
       "         [0.03137255],\n",
       "         [0.03137255]],\n",
       "\n",
       "        [[0.03921569],\n",
       "         [0.03529412],\n",
       "         [0.04313725],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.93333333],\n",
       "         [0.90980392]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.94509804],\n",
       "         [0.94117647],\n",
       "         [0.96470588],\n",
       "         ...,\n",
       "         [0.05098039],\n",
       "         [0.02745098],\n",
       "         [0.03137255]],\n",
       "\n",
       "        [[0.03137255],\n",
       "         [0.02745098],\n",
       "         [0.03529412],\n",
       "         ...,\n",
       "         [0.52941176],\n",
       "         [0.59215686],\n",
       "         [0.23137255]],\n",
       "\n",
       "        [[0.32156863],\n",
       "         [0.38039216],\n",
       "         [0.34509804],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.94117647],\n",
       "         [0.96470588]]],\n",
       "\n",
       "\n",
       "       [[[0.94509804],\n",
       "         [0.94117647],\n",
       "         [0.96470588],\n",
       "         ...,\n",
       "         [0.02745098],\n",
       "         [0.01960784],\n",
       "         [0.01960784]],\n",
       "\n",
       "        [[0.03137255],\n",
       "         [0.02745098],\n",
       "         [0.03529412],\n",
       "         ...,\n",
       "         [0.43529412],\n",
       "         [0.4745098 ],\n",
       "         [0.29411765]],\n",
       "\n",
       "        [[0.3372549 ],\n",
       "         [0.39215686],\n",
       "         [0.32941176],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.93333333],\n",
       "         [0.95294118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0627451 ],\n",
       "         [0.05882353],\n",
       "         [0.06666667],\n",
       "         ...,\n",
       "         [0.03137255],\n",
       "         [0.03137255],\n",
       "         [0.05490196]],\n",
       "\n",
       "        [[0.04705882],\n",
       "         [0.04705882],\n",
       "         [0.04313725],\n",
       "         ...,\n",
       "         [0.04705882],\n",
       "         [0.05490196],\n",
       "         [0.04705882]],\n",
       "\n",
       "        [[0.04705882],\n",
       "         [0.06666667],\n",
       "         [0.05882353],\n",
       "         ...,\n",
       "         [0.02745098],\n",
       "         [0.01960784],\n",
       "         [0.01960784]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "retained-federation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2001/2001 [==============================] - 20784s 10s/step - loss: 0.5024 - accuracy: 0.8351\n",
      "Epoch 2/5\n",
      "2001/2001 [==============================] - 17998s 9s/step - loss: 0.1350 - accuracy: 0.9675\n",
      "Epoch 3/5\n",
      "2001/2001 [==============================] - 3160s 2s/step - loss: 0.0705 - accuracy: 0.9800\n",
      "Epoch 4/5\n",
      "2001/2001 [==============================] - 343s 171ms/step - loss: 0.0726 - accuracy: 0.9815\n",
      "Epoch 5/5\n",
      "2001/2001 [==============================] - 315s 157ms/step - loss: 0.0422 - accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "resnet50 = model.fit(x_train, y_train,\n",
    "epochs=5,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet101\n",
    "base_model = applications.resnet.ResNet101(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "resnet101 = model.fit(x_train, y_train,\n",
    "epochs=5,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = applications.Xception(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "xception101 = model.fit(x_train, y_train,\n",
    "epochs=1,\n",
    "verbose=1, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "oriented-harrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/1\n",
      "2001/2001 [==============================] - 300s 150ms/step - loss: 0.5799 - accuracy: 0.6437\n"
     ]
    }
   ],
   "source": [
    "base_model = applications.VGG16(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "VGG16 = model.fit(x_train, y_train,\n",
    "epochs=1,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "heated-hospital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/1\n",
      "2001/2001 [==============================] - 361s 180ms/step - loss: 0.6318 - accuracy: 0.5947\n"
     ]
    }
   ],
   "source": [
    "base_model = applications.VGG19(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "VGG19 = model.fit(x_train, y_train,\n",
    "epochs=1,\n",
    "batch_size = 32\n",
    ",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-number",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "base_model = applications.InceptionV3(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "inceptionV3 = model.fit(x_train, y_train,\n",
    "epochs=1,\n",
    "batch_size = 32\n",
    ",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "#val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs_range = range(5)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(xtest)\n",
    "y_true=np.argmax(ytest,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001)\n",
    "AlexNet.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "Alexnethistory = AlexNet.fit(xtrain, ytrain,\n",
    "epochs=5,\n",
    "verbose=1,\n",
    "validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from urllib.request import urlopen,urlretrieve\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.datasets import load_files   \n",
    "from keras.utils import np_utils\n",
    "from glob import glob\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras import optimizers\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_height,img_width = 64,64 \n",
    "num_classes = 6\n",
    "#If imagenet weights are being loaded, \n",
    "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
    "base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
